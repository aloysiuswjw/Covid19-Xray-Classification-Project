{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(Categories, datadir):\n",
    "    flat_data_arr=[]\n",
    "    target_arr=[]\n",
    "    for i in Categories:\n",
    "        print(f'loading... category : {i}')\n",
    "        path=os.path.join(datadir,i)\n",
    "        for img in os.listdir(path):\n",
    "            if img.endswith(\".jpg\") or img.endswith(\".png\"):  \n",
    "                img_array=imread(os.path.join(path,img))\n",
    "                img_resized=resize(img_array,(150,150,3))\n",
    "                flat_data_arr.append(img_resized.flatten())\n",
    "                target_arr.append(Categories.index(i))\n",
    "        print(f'loaded category:{i} successfully')\n",
    "    flat_data=np.array(flat_data_arr)\n",
    "    target=np.array(target_arr)\n",
    "    return flat_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=self.input_shape)\n",
    "        model = Sequential()\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units',\n",
    "                                     min_value=32,\n",
    "                                     max_value=512,\n",
    "                                     step=32,\n",
    "                                     default=128),\n",
    "                   activation=hp.Choice(\n",
    "                       'dense_activation',\n",
    "                       values=['relu', 'tanh', 'sigmoid'],\n",
    "                       default='relu')))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.SGD(\n",
    "                hp.Choice('learning_rate',\n",
    "                          values=[1e-2, 1e-3, 1e-4])),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', AUC(name='auc')])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "def create_datagen():\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(tuner, X_train, y_train, X_val, y_val, datagen, epochs):\n",
    "    stop_early = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    tuner.search(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                 validation_data=(X_val, y_val), \n",
    "                 epochs=epochs, callbacks=[stop_early])\n",
    "\n",
    "\n",
    "def get_best_model(tuner):\n",
    "    return tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "    print(f\"Test loss: {loss}\")\n",
    "\n",
    "\n",
    "def model_pipeline(X, y, input_shape, num_classes, epochs=20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=77, stratify=y_train)\n",
    "    X_train = X_train.reshape(-1, 150, 150, 3)\n",
    "    X_val = X_val.reshape(-1, 150, 150, 3)\n",
    "    X_test = X_test.reshape(-1, 150, 150, 3)\n",
    "    X_train = X_train / 255.0\n",
    "    X_val = X_val / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    datagen = create_datagen()\n",
    "    datagen.fit(X_train)\n",
    "    hypermodel = CNNHyperModel(input_shape, num_classes)\n",
    "    tuner = RandomSearch(hypermodel, objective='val_accuracy', max_trials=10, seed=42, directory='random_search')\n",
    "    tuner.search_space_summary()\n",
    "    train_model(tuner, X_train, y_train, X_val, y_val, datagen, epochs)\n",
    "    model = get_best_model(tuner)\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 12m 24s]\n",
      "val_accuracy: 0.5882353186607361\n",
      "\n",
      "Best val_accuracy So Far: 0.5882353186607361\n",
      "Total elapsed time: 00h 48m 54s\n",
      "\n",
      "Search: Running Trial #10\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "352               |352               |units\n",
      "sigmoid           |relu              |dense_activation\n",
      "0.01              |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 45s 5s/step - loss: 0.7014 - accuracy: 0.5830 - auc: 0.6099 - val_loss: 0.7146 - val_accuracy: 0.5882 - val_auc: 0.5882\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.6500 - accuracy: 0.6642 - auc: 0.7038 - val_loss: 0.7037 - val_accuracy: 0.4118 - val_auc: 0.4118\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 48s 5s/step - loss: 0.6169 - accuracy: 0.6900 - auc: 0.7472 - val_loss: 0.8947 - val_accuracy: 0.4118 - val_auc: 0.4118\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.5510 - accuracy: 0.7232 - auc: 0.8067 - val_loss: 1.1383 - val_accuracy: 0.4118 - val_auc: 0.4118\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.5594 - accuracy: 0.7565 - auc: 0.7889 - val_loss: 0.8924 - val_accuracy: 0.4118 - val_auc: 0.4118\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.6368 - accuracy: 0.7380 - auc: 0.7601 - val_loss: 0.9611 - val_accuracy: 0.4118 - val_auc: 0.4118\n",
      "Epoch 7/20\n",
      "1/9 [==>...........................] - ETA: 1:01 - loss: 0.3643 - accuracy: 0.9375 - auc: 0.9141"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "Categories=['covid','normal']\n",
    "datadir='dataset_18/'\n",
    "X, y = load_images(Categories, datadir)\n",
    "y = to_categorical(y)  # one-hot encode the labels\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 2\n",
    "\n",
    "# Run the pipeline\n",
    "model_pipeline(X, y, input_shape, num_classes)\n",
    "\n",
    "# Later, after running the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# For the best model's summary:\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
